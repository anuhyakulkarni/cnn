{"cells":[{"metadata":{},"cell_type":"markdown","source":"the dataset has images of forests,seas,buildings,glaciers,mountains and streets. this notebook attempts to predict them as a particular class/category using CNN layers and keras image preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"#import basic libraries\nimport numpy as np\nimport pandas as pd","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras","execution_count":3,"outputs":[{"output_type":"stream","text":"Using TensorFlow backend.\n","name":"stderr"}]},{"metadata":{},"cell_type":"markdown","source":"**basic understanding about layers used **\n\nSequential:Sequential layer simply acts an inital layer, for the model layers to move in the particular sequence\n\nConvolution2D: it is the first layer of CNN. Convolution is a mathematical operation to merge two sets of information. In our case ,the input image and the feature detector ,are both merged to create a feature map. \n\nMaxPooling2D:maxpooling creates a maxpooling layer, the only argument is the window size.i have used the 3*3 window size.\n\nDense: layer used to add the fully connected layers to neural networks\n\nFlatten: After the convolution and pooling layers we flatten their output to feed into the neural networks\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#import all the essential packages from keras , required for CNN\n\nfrom keras.models import Sequential\nfrom keras.layers import Convolution2D\nfrom keras.layers import MaxPooling2D\nfrom keras.layers import Dense\nfrom keras.layers import Flatten\n\n\n\n","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nclassifier = Sequential()\n\nclassifier.add(Convolution2D(32,(3,3),input_shape=(64,64,3),activation = 'relu'))  # 32 is the number of feature detectors, and 3*3 window\n\nclassifier.add(MaxPooling2D(pool_size=(2,2)))    #size of the sub table ,min is considered = 2*2 \n\nclassifier.add(Flatten())       # flattens the sub table into a linear to be able to fed into training","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier.add(Dense(128,activation = 'relu'))      # first and input layer\nclassifier.add(Dense(6,activation = 'softmax'))    #output layer, 6 is the no of output categories ","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#compile the model\n\nclassifier.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n#sparse categorical bcz the output has multiple catgories","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#image data preprocessing \n\nfrom keras.preprocessing.image import ImageDataGenerator\ntrain_datagen = ImageDataGenerator(\n        rescale=1./255,\n        shear_range=0.2, #shaering transformation\n        zoom_range=0.2,       # zoom in required\n        horizontal_flip=True) #if the images data needs to be horizontally flipped, applicable for real world images\n\ntest_datagen = ImageDataGenerator(rescale=1./255) #rescale the image if necessary (RGB coefficients normalize)\n\n","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#creates the train set\n\ntrain_set = train_datagen.flow_from_directory(\"../input/intel-image-classification/seg_train/seg_train\",\n        target_size=(64,64), #size of the image in the model \n        batch_size=32,\n        class_mode='sparse')\n","execution_count":9,"outputs":[{"output_type":"stream","text":"Found 14034 images belonging to 6 classes.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#creates the test set\ntest_set = test_datagen.flow_from_directory(\n        '../input/intel-image-classification/seg_test/seg_test',\n        target_size=(64,64),       #size of the image in the model\n        batch_size=32,\n        class_mode='binary')","execution_count":10,"outputs":[{"output_type":"stream","text":"Found 3000 images belonging to 6 classes.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#fit the model\n\nclassifier.fit_generator(train_set,\n                    steps_per_epoch=14034,     #number of images\n                    epochs=5,\n                    validation_data=test_set,\n                     validation_steps=3000)","execution_count":11,"outputs":[{"output_type":"stream","text":"Epoch 1/5\n14034/14034 [==============================] - 1237s 88ms/step - loss: 0.4541 - accuracy: 0.8359 - val_loss: 1.2373 - val_accuracy: 0.7663\nEpoch 2/5\n14034/14034 [==============================] - 1197s 85ms/step - loss: 0.1975 - accuracy: 0.9301 - val_loss: 1.6239 - val_accuracy: 0.7492\nEpoch 3/5\n14034/14034 [==============================] - 1193s 85ms/step - loss: 0.1268 - accuracy: 0.9561 - val_loss: 0.7942 - val_accuracy: 0.7601\nEpoch 4/5\n14034/14034 [==============================] - 1196s 85ms/step - loss: 0.0944 - accuracy: 0.9680 - val_loss: 2.2302 - val_accuracy: 0.7524\nEpoch 5/5\n14034/14034 [==============================] - 1197s 85ms/step - loss: 0.0771 - accuracy: 0.9748 - val_loss: 2.2936 - val_accuracy: 0.7704\n","name":"stdout"},{"output_type":"execute_result","execution_count":11,"data":{"text/plain":"<keras.callbacks.callbacks.History at 0x7f906823efd0>"},"metadata":{}}]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}